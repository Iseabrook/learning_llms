{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd99800a-bef3-4a3a-a4e4-49e96f23745e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHELL=/bin/bash\n",
      "SESSION_MANAGER=local/oscar-x230:@/tmp/.ICE-unix/1128,unix/oscar-x230:/tmp/.ICE-unix/1128\n",
      "WINDOWID=65011715\n",
      "QT_ACCESSIBILITY=1\n",
      "COLORTERM=truecolor\n",
      "XDG_CONFIG_DIRS=/etc/xdg/xdg-xubuntu:/etc/xdg:/etc/xdg\n",
      "XDG_SESSION_PATH=/org/freedesktop/DisplayManager/Session0\n",
      "XDG_MENU_PREFIX=xfce-\n",
      "CLUTTER_BACKEND=x11\n",
      "LANGUAGE=en_GB:en\n",
      "SSH_AUTH_SOCK=/run/user/1000/keyring/ssh\n",
      "OPENAI_API_KEY=<OPEN_AI_KEY_HERE>\n",
      "DESKTOP_SESSION=xubuntu\n",
      "SSH_AGENT_PID=1209\n",
      "XDG_SEAT=seat0\n",
      "PWD=/home/oscar/Documents/scripts\n",
      "XDG_SESSION_DESKTOP=xubuntu\n",
      "LOGNAME=oscar\n",
      "QT_QPA_PLATFORMTHEME=gtk2\n",
      "XDG_SESSION_TYPE=x11\n",
      "JPY_SESSION_NAME=/home/oscar/Documents/scripts/Untitled1.ipynb\n",
      "GPG_AGENT_INFO=/run/user/1000/gnupg/S.gpg-agent:0:1\n",
      "_=/usr/bin/env\n",
      "XAUTHORITY=/home/oscar/.Xauthority\n",
      "XDG_GREETER_DATA_DIR=/var/lib/lightdm-data/oscar\n",
      "GDM_LANG=en_GB\n",
      "HOME=/home/oscar\n",
      "LANG=en_GB.UTF-8\n",
      "LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\n",
      "XDG_CURRENT_DESKTOP=XFCE\n",
      "VTE_VERSION=6003\n",
      "FORCE_COLOR=1\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "XDG_SEAT_PATH=/org/freedesktop/DisplayManager/Seat0\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "JPY_PARENT_PID=4527\n",
      "LESSCLOSE=/usr/bin/lesspipe %s %s\n",
      "XDG_SESSION_CLASS=user\n",
      "TERM=xterm-color\n",
      "GTK_OVERLAY_SCROLLING=0\n",
      "LESSOPEN=| /usr/bin/lesspipe %s\n",
      "USER=oscar\n",
      "GIT_PAGER=cat\n",
      "DISPLAY=:0.0\n",
      "SHLVL=1\n",
      "PAGER=cat\n",
      "QT_QPA_FONTDIR=/home/oscar/.local/lib/python3.8/site-packages/cv2/qt/fonts\n",
      "XDG_VTNR=7\n",
      "XDG_SESSION_ID=c2\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "LD_LIBRARY_PATH=/home/oscar/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "XDG_RUNTIME_DIR=/run/user/1000\n",
      "XDG_DATA_DIRS=/usr/share/xubuntu:/usr/share/xfce4:/usr/local/share:/usr/share:/var/lib/snapd/desktop:/usr/share\n",
      "PATH=/home/oscar/.local/bin:/home/oscar/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "QT_QPA_PLATFORM_PLUGIN_PATH=/home/oscar/.local/lib/python3.8/site-packages/cv2/qt/plugins\n",
      "GDMSESSION=xubuntu\n",
      "DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus\n"
     ]
    }
   ],
   "source": [
    "#from https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb\n",
    "# !pip install -- update chromadb langchain\n",
    "# !pip show chromadb langchain\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '<OPEN_AI_KEY_HERE>'\n",
    "\n",
    "# Access the environment variable later in your code\n",
    "\n",
    "!env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3618c193-add0-4171-977e-e9a378f437bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "from typing import Any\n",
    "import chromadb\n",
    "import chromadb.config\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a632b76-8c37-481d-933c-5058e1c5e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Get elements\n",
    "\n",
    "\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=\"/home/oscar/Documents/scripts/Recommendations_of_the_Taskforce_on_Nature-related_Financial_Disclosures_September_2023.pdf\",\n",
    "    # Unstructured first finds embedded image blocks\n",
    "    extract_images_in_pdf=False,\n",
    "    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "    # Titles are any sub-section of the document\n",
    "    infer_table_structure=True,\n",
    "    # Post processing to aggregate text once we have the title\n",
    "    chunking_strategy=\"by_title\",\n",
    "    # Chunking params to aggregate text blocks\n",
    "    # Attempt to create a new chunk 3800 chars\n",
    "    # Attempt to keep chunks > 2000 chars\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=\"/home/oscar/Documents/scripts/outputs/\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32d219e-aba4-48fc-bd31-4316398921b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 147,\n",
       " \"<class 'unstructured.documents.elements.Table'>\": 50}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6a7037-fd14-4526-b56f-f61c27bc52af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "class Element(BaseModel):\n",
    "    type: str\n",
    "    text: Any\n",
    "\n",
    "\n",
    "# Categorize by type\n",
    "categorized_elements = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"table\", text=str(element)))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
    "\n",
    "# Tables\n",
    "table_elements = [e for e in categorized_elements if e.type == \"table\"]\n",
    "print(len(table_elements))\n",
    "\n",
    "# Text\n",
    "text_elements = [e for e in categorized_elements if e.type == \"text\"]\n",
    "print(len(text_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed7e643c-0839-473b-befe-20cf4e53207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "import time\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\ \n",
    "Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Summary chain\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", api_key='<OPEN_AI_KEY_HERE>')\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cfa51e-da8f-4c36-b12a-142b00d4a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to tables\n",
    "tables = [i.text for i in table_elements]\n",
    "# print(tables[0:3])\n",
    "# table_summaries = summarize_chain.batch(tables[0:2], {\"max_concurrency\": 2})\n",
    "# table_summaries\n",
    "\n",
    "# table_list=[]\n",
    "# i=0\n",
    "# for table in tables: \n",
    "#     i+=1\n",
    "#     table_summary = summarize_chain.invoke(table)\n",
    "#     table_list.append(table_summary)\n",
    "#     if i==4|i==5:\n",
    "#         time.sleep(60) \n",
    "#         i=0\n",
    "# # table_list\n",
    "# print(len(table_list))\n",
    "# print(len(tables))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4ab4051-4bff-4115-9552-28b76f8e94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to texts`1\n",
    "texts = [i.text for i in text_elements]\n",
    "# text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "\n",
    "# text_list=[]\n",
    "# i=0\n",
    "# for text in texts[145:]: \n",
    "#     i+=1\n",
    "#     text_summary = summarize_chain.invoke(text)\n",
    "#     print(text_summary)\n",
    "#     text_list.append(text_summary)\n",
    "#     if i==5:\n",
    "#         time.sleep(10) \n",
    "#         i=0\n",
    "# len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "805d9943-c78f-4006-b4de-e073cabae5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"text_list.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(text_list, f, indent=2) \n",
    "\n",
    "with open(\"table_list.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(table_list, f, indent=2) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317d2617-f3c2-49a2-8dc9-988b82bad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"text_list.json\", 'r') as f:\n",
    "    text_list = json.load(f)\n",
    "\n",
    "with open(\"table_list.json\", 'r') as f:\n",
    "    table_list = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cdc52cb-30ee-4cd4-a74d-3e1adc804db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding to vector store \n",
    "\n",
    "# import os\n",
    "# import openai\n",
    " \n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "from langchain.vectorstores import Chroma \n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(text_list)\n",
    "]\n",
    "\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "    for i, s in enumerate(table_list)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8974090-9661-4bdd-8306-0c20064938ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run RAG \n",
    "\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Prompt template\n",
    "template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f9d418-90bd-4726-a4e3-fcb7f93b8c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The key principles of the TNFD are as follows:\\n\\n1. Globally inclusive: The framework and approach should be relevant and accessible worldwide, across emerging and developed markets.\\n\\n2. Market usability: The framework should be directly usable and valuable to market participants, including corporates and financial institutions, as well as policy and other actors.\\n\\n3. Science-based: The framework should follow a scientifically anchored approach, incorporating well-established and emerging scientific evidence, and converging towards other existing science-based initiatives.\\n\\n4. Nature-related risks: The framework should embrace nature-related risks, including immediate and material financial risks, as well as nature dependencies and impacts and their related organizational and societal risks.\\n\\n5. Purpose driven: The framework should actively reduce risks and increase nature-positive action by using the minimum required level of granularity to ensure the achievement of the TNFD goal.\\n\\n6. Integrated and adaptive: The framework should be able to be integrated into and enhance existing disclosures and other standards. It should also account for and be adaptive to changes in national and international policy commitments, standards, and market conditions.\\n\\n7. Climate-nature nexus: The framework should employ an integrated approach to climate- and nature-related risks, scaling up finance for nature-based solutions.\\n\\nThese principles guide the development of the TNFD's risk management and disclosure framework.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain.invoke(\"What are the key principles of the TNFD? Produce your answer in markdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fa59966-9a9c-4603-afa0-11427a25e3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The TNFD, which stands for Taskforce on Nature-related Financial Disclosures, is a group of people who are working together to help organizations understand and talk about the impact they have on nature. They want to make sure that companies and other groups are aware of how their actions can affect the environment and the plants and animals that live in it. The TNFD is creating a set of guidelines and recommendations to help organizations report on their impact on nature and take steps to protect it. They are also working with scientists and experts to make sure their recommendations are based on the best available information.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Explain the TNFD to a 5 year old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f96948d9-36af-43b7-8fc7-be5f79ebfee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next phase priorities for the TNFD are outlined in Table 5.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are the next phase priorities for the TNFD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "808bf550-9981-4835-b440-8f286a955503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Element(type='table', text='Category Description Acute risks Occurrenceofshortterm,specificeventsthatchangethestateofnature.Forexample,oilspills, forestfiresorpestsaffectingaharvest. Chronic risks Gradual changes to the state of nature. For example, pollution stemming from pesticide use or climate change.')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_elements[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e272ae1-ebd1-4a62-844e-a22e61857217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The table describes two categories of risks: acute risks, which are short-term events that change the state of nature, such as oil spills or forest fires, and chronic risks, which are gradual changes to the state of nature, such as pollution from pesticide use or climate change.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b45e894-4850-4c75-9756-1be62f32ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiVectorRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7face384a400>, docstore=<langchain.storage.in_memory.InMemoryBaseStore object at 0x7facea126880>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65505d8a-863f-46c1-abd9-92dc0e8eddf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
